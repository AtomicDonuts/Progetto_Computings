{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Tuning and Training\n",
    "by Pasquale Napoli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa colonna assicura che tutti i file siano presenti se il codice è lanciato su colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Colab Detected\")\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if not gpus:\n",
    "        raise RuntimeError(\"Nessuna GPU trovata.Controlla di aver selezionato il runtime giusto.\")\n",
    "    else:\n",
    "        print(f\"Trovate {len(gpus)} GPU:\\n{gpus}\")\n",
    "    \n",
    "    !git clone https://github.com/AtomicDonuts/Progetto_Computings.git\n",
    "    %cd Progetto_Computings/\n",
    "    !pip install -q -r requirements.txt\n",
    "    !python3 fits_import/fits2csv.py\n",
    "\n",
    "    git_dir = None\n",
    "    for i in Path(__file__).parents:\n",
    "        for j in i.iterdir():\n",
    "            if \".git\" in j.as_posix() and j.is_dir():\n",
    "                git_dir = i\n",
    "    if git_dir is None:\n",
    "        raise FileNotFoundError(\n",
    "            \"Git Directory Not Found. Please ensure that you cloned the repository in the right way.\"\n",
    "        )\n",
    "    import_dir = git_dir / \"imports/\"\n",
    "    sys.path.append(import_dir.as_posix())\n",
    "    import nn_models as ann\n",
    "    import custom_variables as custom_paths\n",
    "    import metrics as met\n",
    "else:\n",
    "    git_dir = None\n",
    "    for i in Path(__file__).parents:\n",
    "        for j in i.iterdir():\n",
    "            if \".git\" in j.as_posix() and j.is_dir():\n",
    "                git_dir = i\n",
    "    if git_dir is None:\n",
    "        raise FileNotFoundError(\n",
    "            \"Git Directory Not Found. Please ensure that you cloned the repository in the right way.\"\n",
    "        )\n",
    "    import_dir = git_dir / \"imports/\"\n",
    "    sys.path.append(import_dir.as_posix())\n",
    "    import nn_models as ann\n",
    "    import custom_variables as custom_paths\n",
    "    import metrics as met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import clone_model\n",
    "import keras_tuner as kt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importazione del Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(custom_paths.csv_path)\n",
    "df = df[(df[\"CLASS_GENERIC\"] == \"AGN\") | (df[\"CLASS_GENERIC\"] == \"Pulsar\")]\n",
    "print(f\"Sample Size: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La rete non può prendere in input delle stringhe, quindi utilizzando \"SpectrumType\" si creano 3 colonne booleane, una per ogni tipo di spettro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PowerLaw\"] = np.where(df[\"SpectrumType\"] == \"PowerLaw\",1,0,)\n",
    "df[\"LogParabola\"] = np.where(df[\"SpectrumType\"] == \"LogParabola\",1,0,)\n",
    "df[\"PLSuperExpCutoff\"] = np.where(df[\"SpectrumType\"] == \"PLSuperExpCutoff\",1,0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poi si scelgono le colonne che vogliamo usare nell'addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_input1 = [\"GLAT\",\"Variability_Index\" ,\"PowerLaw\",\"LogParabola\",\"PLSuperExpCutoff\"]\n",
    "col_flux_band = np.array([[f\"Flux_Band_{i}\", f\"Sqrt_TS_Band_{i}\"] for i in range(8)])\n",
    "col_flux_hist = np.array([[f\"Flux_History_{i}\", f\"Sqrt_TS_History_{i}\"] for i in range(14)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizziamo le colonne usando lo scaler, in modo che abbiano media = 0 e sigma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cols = np.array(list(col_flux_band.flatten()) + list(col_flux_hist.flatten()))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[norm_cols])\n",
    "scaled_data = scaler.transform(df[norm_cols])\n",
    "df[norm_cols] = scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo quindi gli array per l'addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_additional = df[col_input1].to_numpy()\n",
    "input_flux_band = df[col_flux_band.flatten()].to_numpy()\n",
    "input_flux_hist = df[col_flux_hist.flatten()].to_numpy()\n",
    "print(f\"Additionl Size: {input_additional.shape}\")\n",
    "print(f\"Flux_Band Size: {input_flux_band.shape}\")\n",
    "print(f\"Flux_History Size: {input_flux_hist.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione delle label, scegliendo \"Pulsar\" come Vero Positivo (1) e \"AGN\" come Vero Negativo (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_agn = df[\"CLASS_GENERIC\"].to_numpy() == \"AGN\"\n",
    "labels = np.zeros((len(df)), dtype=int)\n",
    "labels[~is_agn] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dato che la distribuzione delle due classi è sbilanciate, 4000 AGN vs 300 Pulsar, creiamo dei pesi da dare al tuner, in modo da migliorare l'addestramento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=np.unique(labels), y=labels\n",
    ")\n",
    "class_weight = {index: value for index, value in enumerate(class_weight)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splittiamo il dataset in 75%-25%, dove il 25% verrà usato alla fine per l'inferenza\n",
    "Lo split è fatto usando la fuznione dello StratifiedKFold, in questo modo assicuriamo un uguale rapporto di classi in entrambi i dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitdata = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "train, test = next(splitdata.split(np.zeros(len(labels)), labels))\n",
    "\n",
    "fb = input_flux_band[train]\n",
    "hb = input_flux_hist[train]\n",
    "ia = input_additional[train]\n",
    "lab = labels[train]\n",
    "vfb =  input_flux_band[test]\n",
    "vhb =  input_flux_hist[test]\n",
    "via = input_additional[test]\n",
    "vlab = labels[test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo i parametri della ricerca per il Tuner e lo facciamo partire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    ann.hp_final_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    overwrite=False,\n",
    "    directory=\"Progetto\",\n",
    "    project_name=\"TripleInput\",\n",
    ")\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "tuner.search(\n",
    "    x=[fb, hb, ia],\n",
    "    y=lab,\n",
    "    epochs=50,\n",
    "    validation_split=0.5,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[stop_early],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendiamo il miglior modello trovato dal tuner (quello con la validation loss minore) e ne salviamo il learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_lr = best_model.optimizer.learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo una serie di array in cui verranno immagazzinate le metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_k_array = []\n",
    "auc_k_array = []\n",
    "accuracy_k_array = []\n",
    "acc_agn_k_array = []\n",
    "acc_psr_k_array = []\n",
    "eq_th_k_array =[]\n",
    "eq_acc_agn_k_array = []\n",
    "eq_acc_psr_k_array = []\n",
    "f1_k_array = []\n",
    "th_k_array = []\n",
    "cm_k_array = []\n",
    "\n",
    "loss_all_array = []\n",
    "auc_all_array = []\n",
    "accuracy_all_array = []\n",
    "acc_agn_all_array = []\n",
    "acc_psr_all_array = []\n",
    "eq_th_all_array = []\n",
    "eq_acc_agn_all_array = []\n",
    "eq_acc_psr_all_array = []\n",
    "f1_all_array = []\n",
    "th_all_array = []\n",
    "cm_all_array = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si esegue lo Stratified 10 Fold sul modello migliore di iperparametri, ma resettando i pesi a valori casuali.\n",
    "Il learning rate però rimane lo stesso trovato prima. \n",
    "Le metriche vengono salvate negli array, in modo tale da poterne fare la media e l'errore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_no = 0\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "for ktrain, ktest in skf.split(np.zeros(len(lab)), lab):\n",
    "    k_hb   = hb[ktrain]\n",
    "    k_fb   = fb[ktrain]\n",
    "    k_ia   = ia[ktrain]\n",
    "    k_lab  = lab[ktrain]\n",
    "    k_vfb  =  fb[ktest]\n",
    "    k_vhb  =  hb[ktest]\n",
    "    k_via  =  ia[ktest]\n",
    "    k_vlab = lab[ktest]\n",
    "\n",
    "    reset_model = clone_model(best_model)\n",
    "    reset_model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\n",
    "            \"accuracy\",\n",
    "            \"auc\",\n",
    "        ],\n",
    "    )\n",
    "    reset_model.optimizer.learning_rate = best_lr\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5)\n",
    "\n",
    "    history = reset_model.fit(\n",
    "        x=[k_fb, k_hb, k_ia],\n",
    "        y=k_lab,\n",
    "        epochs=300,\n",
    "        validation_data=[[k_vfb, k_vhb, k_via], k_vlab],\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "    print(f\"Fold No.{fold_no}\")\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Prediction on Fold\")\n",
    "    scores = reset_model.evaluate([k_vfb, k_vhb, k_via], k_vlab)\n",
    "    predictions = reset_model.predict([k_vfb, k_vhb, k_via])\n",
    "\n",
    "    loss_k_array.append(scores[0])\n",
    "    auc_k_array.append(scores[1])\n",
    "    print(f\"Loss: {scores[0]}\")\n",
    "    print(f\"AUC {scores[2]}\")\n",
    "\n",
    "    acc, th = met.best_accuracy(k_vlab, predictions)\n",
    "    accuracy_k_array.append(acc)\n",
    "    th_k_array.append(th)\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "\n",
    "    f1_score = met.f1_score(th,k_vlab, predictions)\n",
    "    f1_k_array.append(f1_score)\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "    eq_acc_agn,eq_acc_psr, eq_th = met.best_eq_accuracy(k_vlab, predictions)\n",
    "    eq_th_k_array.append(eq_th)\n",
    "    eq_acc_agn_k_array.append(eq_acc_agn)\n",
    "    eq_acc_psr_k_array.append(eq_acc_psr)\n",
    "    print(f\"EqAcc AGN: {eq_acc_agn}\")\n",
    "    print(f\"EqAcc PSR: {eq_acc_psr}\")\n",
    "\n",
    "    acc_agn, acc_psr = met.class_accuracy(th, k_vlab, predictions)\n",
    "    acc_agn_k_array.append(acc_agn)\n",
    "    acc_psr_k_array.append(acc_psr)\n",
    "    print(f\"Accuracy AGN: {acc_agn} Accuracy PSR: {acc_psr}\")\n",
    "\n",
    "    th_pred = (predictions >= th).astype(int)\n",
    "    cm_sing = met.sk_metrics.confusion_matrix(k_vlab, th_pred)\n",
    "    print(cm_sing)\n",
    "    cm_k_array.append(cm_sing)\n",
    "\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "\n",
    "    print(\"Prediction on Evaluation Dataset\")\n",
    "    scores = reset_model.evaluate([vfb, vhb, via], vlab)\n",
    "    predictions = reset_model.predict([vfb, vhb, via])\n",
    "\n",
    "    loss_all_array.append(scores[0])\n",
    "    auc_all_array.append(scores[1])\n",
    "    print(f\"Loss: {scores[0]}\")\n",
    "    print(f\"AUC {scores[2]}\")\n",
    "\n",
    "    acc, th = met.best_accuracy(vlab, predictions)\n",
    "    accuracy_all_array.append(acc)\n",
    "    th_all_array.append(th)\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "\n",
    "    f1_score = met.f1_score(th, vlab, predictions)\n",
    "    f1_all_array.append(f1_score)\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "    eq_acc_agn,eq_acc_psr, eq_th = met.best_eq_accuracy(vlab, predictions)\n",
    "    eq_th_all_array.append(eq_th)\n",
    "    eq_acc_agn_all_array.append(eq_acc_agn)\n",
    "    eq_acc_psr_all_array.append(eq_acc_psr)\n",
    "    print(f\"EqAcc AGN: {eq_acc_agn}\")\n",
    "    print(f\"EqAcc PSR: {eq_acc_psr}\")\n",
    "\n",
    "    acc_agn, acc_psr = met.class_accuracy(th, vlab, predictions)\n",
    "    acc_agn_all_array.append(acc_agn)\n",
    "    acc_psr_all_array.append(acc_psr)\n",
    "    print(f\"Accuracy AGN: {acc_agn} Accuracy PSR: {acc_psr}\")\n",
    "\n",
    "    th_pred = (predictions >= th).astype(int)\n",
    "    cm_sing = met.sk_metrics.confusion_matrix(vlab, th_pred)\n",
    "    print(cm_sing)\n",
    "    cm_all_array.append(cm_sing)\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "\n",
    "    modelpath = custom_paths.dir_models_path / f\"TripleFolf{fold_no}.keras\"\n",
    "    reset_model.save(modelpath)\n",
    "\n",
    "    fold_no = fold_no + 1\n",
    "# end for\n",
    "cm_k_array = np.array(cm_k_array)\n",
    "cm_all_array = np.array(cm_all_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print di tutte i valori delle metriche trovate.\n",
    "Viene anche detto qual è il migliore tra i 10 modelli allenati.\n",
    "Quello verrà utilizzato per l'inferenza nello script prediction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Model Was: {np.argmax(f1_all_array)}. Based on F1Score\")\n",
    "print(\"------------------------------------------------------------------------\\n\")\n",
    "print(\"Average scores for all folds:\")\n",
    "print(\"Prediction on Fold\")\n",
    "print(f\"> Loss: {np.mean(loss_k_array)}(+- {np.std(loss_k_array)})\")\n",
    "print(f\"> AUC: {np.mean(auc_k_array)} (+- {np.std(auc_k_array)})\")\n",
    "print(f\"> Accuracy: {np.mean(accuracy_k_array)} (+- {np.std(accuracy_k_array)})\")\n",
    "print(f\"> F1: {np.mean(f1_k_array)} (+- {np.std(f1_k_array)})\")\n",
    "print(f\"> EqAcc AGN: {np.mean(eq_acc_agn_k_array)} (+- {np.std(eq_acc_agn_k_array)})\")\n",
    "print(f\"> EqAcc PSR: {np.mean(eq_acc_psr_k_array)} (+- {np.std(eq_acc_psr_k_array)})\")\n",
    "print(f\"> Acc AGN: {np.mean(acc_agn_k_array)} (+- {np.std(acc_agn_k_array)})\")\n",
    "print(f\"> Acc PSR: {np.mean(acc_psr_k_array)} (+- {np.std(acc_psr_k_array)})\")\n",
    "print(\"Confution Matrix\")\n",
    "print(f\"{np.mean(cm_k_array[:,0,0])}+-{np.std(cm_k_array[:,0,0])}\\t{np.mean(cm_k_array[:,0,1])}+-{np.std(cm_k_array[:,0,1])}\")\n",
    "print(f\"{np.mean(cm_k_array[:,1,0])}+-{np.std(cm_k_array[:,1,0])}\\t{np.mean(cm_k_array[:,1,1])}+-{np.std(cm_k_array[:,1,1])}\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Prediction on Evaluation DataSet\")\n",
    "print(f\"> Loss: {np.mean(loss_all_array)}(+- {np.std(loss_all_array)})\")\n",
    "print(f\"> AUC: {np.mean(auc_all_array)} (+- {np.std(auc_all_array)})\")\n",
    "print(f\"> Accuracy: {np.mean(accuracy_all_array)} (+- {np.std(accuracy_all_array)})\")\n",
    "print(f\"> F1: {np.mean(f1_all_array)} (+- {np.std(f1_all_array)})\")\n",
    "print(f\"> EqAcc AGN: {np.mean(eq_acc_agn_all_array)} (+- {np.std(eq_acc_agn_all_array)})\")\n",
    "print(f\"> EqAcc PSR: {np.mean(eq_acc_psr_all_array)} (+- {np.std(eq_acc_psr_all_array)})\")\n",
    "print(f\"> Acc AGN: {np.mean(acc_agn_all_array)} (+- {np.std(acc_agn_all_array)})\")\n",
    "print(f\"> Acc PSR: {np.mean(acc_psr_all_array)} (+- {np.std(acc_psr_all_array)})\")\n",
    "print(\"Confution Matrix\")\n",
    "print(f\"{np.mean(cm_all_array[:,0,0])}+-{np.std(cm_all_array[:,0,0])}\\t{np.mean(cm_all_array[:,0,1])}+-{np.std(cm_all_array[:,0,1])}\")\n",
    "print(f\"{np.mean(cm_all_array[:,1,0])}+-{np.std(cm_all_array[:,1,0])}\\t{np.mean(cm_all_array[:,1,1])}+-{np.std(cm_all_array[:,1,1])}\")\n",
    "print(\"------------------------------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
