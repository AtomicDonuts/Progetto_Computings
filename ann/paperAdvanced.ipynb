{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d3fc460",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    print(\"Colab Detected\")\n",
        "    import tensorflow as tf\n",
        "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "    if not gpus:\n",
        "        raise RuntimeError(\"Nessuna GPU trovata.Controlla di aver selezionato il runtime giusto.\")\n",
        "    else:\n",
        "        print(f\"Trovate {len(gpus)} GPU:\\n{gpus}\")\n",
        "    \n",
        "    !git clone https://github.com/AtomicDonuts/Progetto_Computings.git\n",
        "    %cd Progetto_Computings/\n",
        "    !pip install -r requirements.txt\n",
        "    !python3 fits_import/fits2csv.py\n",
        "    \n",
        "    sys.path.append(\"imports/\")\n",
        "    import custom_variables as custom_paths\n",
        "else:\n",
        "    print(\"Local Machine Detected\")\n",
        "    sys.path.append(\"../imports/\")\n",
        "    import custom_variables as custom_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a83728e",
      "metadata": {
        "id": "2a83728e"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Input, Concatenate,Flatten, Dropout\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed6986ad",
      "metadata": {
        "id": "ed6986ad"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(custom_paths.csv_path)\n",
        "df = df[(df[\"CLASS_GENERIC\"] == \"AGN\") | (df[\"CLASS_GENERIC\"] == \"Pulsar\")]\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8be5d5c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "flux_band = np.array([[f\"Flux_Band_{i}\", f\"Sqrt_TS_Band_{i}\"] for i in range(8)])\n",
        "flux_hist = np.array([[f\"Flux_History_{i}\", f\"Sqrt_TS_History_{i}\"] for i in range(14)])\n",
        "norm_cols = np.array( ([[f\"Flux_Band_{i}\", f\"Sqrt_TS_Band_{i}\"] for i in range(8)] + [[f\"Flux_History_{i}\", f\"Sqrt_TS_History_{i}\"] for i in range(14)])).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "290fa662",
      "metadata": {},
      "outputs": [],
      "source": [
        "drop = df[norm_cols][np.array(np.isinf(df[norm_cols]).any(axis=1))].index\n",
        "if len(drop):\n",
        "    df = df.drop(drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7005ffaa",
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(df[norm_cols])\n",
        "scaled_data = scaler.transform(df[norm_cols])\n",
        "df[norm_cols] = scaled_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e28f0fd4",
      "metadata": {},
      "outputs": [],
      "source": [
        "flux_band = np.dstack((df[flux_band[:, 0]].to_numpy(), df[flux_band[:, 1]].to_numpy()))\n",
        "flux_hist = np.dstack((df[flux_hist[:, 0]].to_numpy(), df[flux_hist[:, 1]].to_numpy()))\n",
        "print(f\"Flux_Band Size: {flux_band.shape}\")\n",
        "print(f\"Flux_History Size: {flux_hist.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ad69e72",
      "metadata": {},
      "outputs": [],
      "source": [
        "# La logica delle label nel paper non è spiegato bene, dall'output suppongo sia così\n",
        "# Label = [ProbAGN,ProbPSR]\n",
        "# Per AGN Label = [1,0]\n",
        "# Per PSR Label = [0,1]\n",
        "\n",
        "is_agn = df[\"CLASS_GENERIC\"].to_numpy() == \"AGN\"\n",
        "is_psr = df[\"CLASS_GENERIC\"].to_numpy() == \"Pulsar\"\n",
        "labels = np.zeros((len(df), 2), dtype=int)\n",
        "labels[is_agn, 0] = 1\n",
        "labels[is_psr, 1] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "705a69fc",
      "metadata": {
        "id": "705a69fc"
      },
      "outputs": [],
      "source": [
        "model_name = \"Modello_DNN_Paper_Modificato\"\n",
        "\n",
        "inputs = Input(shape=flux_band.shape[1:],name= \"Input_flux_band\")\n",
        "hidden = Flatten(name = \"Flatten_flux_band\")(inputs)\n",
        "hidden = Dense(32, activation=\"relu\", name = \"Dense_flux_band\")(hidden)\n",
        "hidden = Dropout(0.3, name = \"Dropout_flux_band\")(hidden)\n",
        "hidden = Dense(16, activation=\"relu\", name=\"Dense2_flux_band\")(hidden)\n",
        "\n",
        "inputs2 = Input(shape=flux_hist.shape[1:], name=\"Input_flux_hist\")\n",
        "hidden2 = Flatten(name=\"Flatten_flux_hist\")(inputs2)\n",
        "hidden2 = Dense(32, activation=\"relu\", name=\"Dense_flux_hist\")(hidden2)\n",
        "hidden2 = Dropout(0.3, name=\"Dropout_flux_hist\")(hidden2)\n",
        "hidden2 = Dense(16, activation=\"relu\", name=\"Dense2_flux_hist\")(hidden2)\n",
        "\n",
        "concat = Concatenate(name = \"Concatenate\")([hidden2, hidden])\n",
        "concat = Dropout(0.7, name = \"Dropout_concat\")(concat)\n",
        "final_hidden = Dense(16, activation=\"relu\", name=\"Dense_concat\")(concat)\n",
        "final_hidden = Dense(4, activation=\"relu\",name = \"Dense_final\")(final_hidden)\n",
        "outputs = Dense(2, activation=\"softmax\", name = \"Output\")(final_hidden)\n",
        "\n",
        "model_paper = Model(inputs=[inputs, inputs2], outputs=outputs, name=model_name)\n",
        "model_paper.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "model_paper.optimizer.learning_rate = 0.01\n",
        "\n",
        "model_paper.summary()\n",
        "plot_model(model_paper, to_file= f\"{model_name}.png\", show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d11794b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model_paper.fit(\n",
        "    [flux_band, flux_hist],\n",
        "    labels,\n",
        "    batch_size=64,\n",
        "    validation_split=0.5,\n",
        "    epochs=150,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4756880",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd6919c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model_paper.predict([flux_band, flux_hist])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "514841c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_predicted_agn = (predictions[:, 0] > 0.6) & (predictions[:, 1] < 0.1)\n",
        "mask_predicted_psr = (predictions[:, 0] < 0.1) & (predictions[:, 1] > 0.6)\n",
        "mat_h = np.vstack([is_agn, is_psr])\n",
        "mat_v = np.array([mask_predicted_agn, mask_predicted_psr])\n",
        "# 2 ore per creare sta linea di codice di merda\n",
        "mat_vectorized = mat_h[:, None, :] & mat_v[None, :, :]\n",
        "confusion_matrix = mat_vectorized.sum(axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67661f3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "TOT = len(predictions)\n",
        "TN = confusion_matrix[0,0]\n",
        "FP = confusion_matrix[0,1]\n",
        "FN = confusion_matrix[1,0]\n",
        "TP = confusion_matrix[1,1]\n",
        "print(\n",
        "    f\"Data under the cutoff: {TOT - (TN + FP + FN + TP)} ie {np.round(((TOT - (TN + FP + FN + TP))/TOT) * 100,2)}%\"\n",
        ")\n",
        "print(f\"Accurcy: {(TP + TN) / (TN + FP + FN + TP)}\")\n",
        "print(f\"F1 Score: {TP/(TP + 0.5*(FP+FN))}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
