{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b41a43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Machine Detected\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Colab Detected\")\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if not gpus:\n",
    "        raise RuntimeError(\"Nessuna GPU trovata.Controlla di aver selezionato il runtime giusto.\")\n",
    "    else:\n",
    "        print(f\"Trovate {len(gpus)} GPU:\\n{gpus}\")\n",
    "    \n",
    "    !git clone https://github.com/AtomicDonuts/Progetto_Computings.git\n",
    "    %cd Progetto_Computings/\n",
    "    !git checkout modell\n",
    "    !pip install -q -r requirements.txt\n",
    "    !python3 fits_import/fits2csv.py\n",
    "    \n",
    "    sys.path.append(\"imports/\")\n",
    "    import nn_models as ann\n",
    "    import custom_variables as custom_paths\n",
    "    import metrics as met\n",
    "else:\n",
    "    print(\"Local Machine Detected\")\n",
    "    sys.path.append(\"../imports/\")\n",
    "    import nn_models as ann\n",
    "    import custom_variables as custom_paths\n",
    "    import metrics as met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e936141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a847fcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 4334\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(custom_paths.csv_path)\n",
    "df = df[(df[\"CLASS_GENERIC\"] == \"AGN\") | (df[\"CLASS_GENERIC\"] == \"Pulsar\")]\n",
    "print(f\"Sample Size: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd004210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PowerLaw\"] = np.where(df[\"SpectrumType\"] == \"PowerLaw\",1,0,)\n",
    "df[\"LogParabola\"] = np.where(df[\"SpectrumType\"] == \"LogParabola\",1,0,)\n",
    "df[\"PLSuperExpCutoff\"] = np.where(df[\"SpectrumType\"] == \"PLSuperExpCutoff\",1,0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b556b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_input1 = [\"GLAT\", \"PowerLaw\",\"LogParabola\",\"PLSuperExpCutoff\" ,\"Variability_Index\"]\n",
    "col_flux_band = np.array([[f\"Flux_Band_{i}\", f\"Sqrt_TS_Band_{i}\"] for i in range(8)])\n",
    "col_flux_hist = np.array([[f\"Flux_History_{i}\", f\"Sqrt_TS_History_{i}\"] for i in range(14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "358a5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cols = np.array(list(col_flux_band.flatten()) + list(col_flux_hist.flatten()))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[norm_cols])\n",
    "scaled_data = scaler.transform(df[norm_cols])\n",
    "df[norm_cols] = scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "311ade31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additionl Size: (4334, 5)\n",
      "Flux_Band Size: (4334, 16)\n",
      "Flux_History Size: (4334, 28)\n"
     ]
    }
   ],
   "source": [
    "input_additional = df[col_input1].to_numpy()\n",
    "input_flux_hist = df[col_flux_hist.flatten()].to_numpy()\n",
    "input_flux_band = df[col_flux_band.flatten()].to_numpy()\n",
    "print(f\"Additionl Size: {input_additional.shape}\")\n",
    "print(f\"Flux_Band Size: {input_flux_band.shape}\")\n",
    "print(f\"Flux_History Size: {input_flux_hist.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8178810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_agn = df[\"CLASS_GENERIC\"].to_numpy() == \"AGN\"\n",
    "\n",
    "labels = np.zeros((len(df)), dtype=int)\n",
    "labels[~is_agn] = 1\n",
    "\n",
    "labels_double = np.zeros((len(df), 2), dtype=int)\n",
    "labels_double[is_agn, 0] = 1\n",
    "labels_double[~is_agn, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7500f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weight = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=np.unique(labels), y=labels\n",
    ")\n",
    "class_weight = {index: value for index, value in enumerate(class_weight)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab8baa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=2,shuffle=True)\n",
    "train,test = next(skf.split(np.zeros(len(labels)),labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4df8a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ann.final_model(input_flux_band.shape[1:],input_flux_hist.shape[1:],input_additional.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64f98d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.6945 - auc: 0.4848 - loss: 0.8549 - val_accuracy: 0.9419 - val_auc: 0.5027 - val_loss: 0.3518 - learning_rate: 0.0100\n",
      "Epoch 2/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9702 - auc: 0.4799 - loss: 0.4705 - val_accuracy: 0.9419 - val_auc: 0.4946 - val_loss: 0.4327 - learning_rate: 0.0100\n",
      "Epoch 3/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9821 - auc: 0.4992 - loss: 0.3388 - val_accuracy: 0.9419 - val_auc: 0.5229 - val_loss: 0.4478 - learning_rate: 0.0100\n",
      "Epoch 4/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9757 - auc: 0.5727 - loss: 0.4225 - val_accuracy: 0.9419 - val_auc: 0.5065 - val_loss: 0.4249 - learning_rate: 0.0100\n",
      "Epoch 5/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9773 - auc: 0.6861 - loss: 0.3624 - val_accuracy: 0.9419 - val_auc: 0.5247 - val_loss: 0.4053 - learning_rate: 0.0100\n",
      "Epoch 6/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9796 - auc: 0.5855 - loss: 0.3440 - val_accuracy: 0.9419 - val_auc: 0.5083 - val_loss: 0.4253 - learning_rate: 0.0100\n",
      "Epoch 7/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9757 - auc: 0.6182 - loss: 0.3654 - val_accuracy: 0.9419 - val_auc: 0.5335 - val_loss: 0.3823 - learning_rate: 0.0050\n",
      "Epoch 8/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9716 - auc: 0.6971 - loss: 0.3886 - val_accuracy: 0.9419 - val_auc: 0.5394 - val_loss: 0.3759 - learning_rate: 0.0050\n",
      "Epoch 9/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9688 - auc: 0.7029 - loss: 0.4255 - val_accuracy: 0.9419 - val_auc: 0.5324 - val_loss: 0.3576 - learning_rate: 0.0050\n",
      "Epoch 10/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9684 - auc: 0.6730 - loss: 0.4118 - val_accuracy: 0.9419 - val_auc: 0.5323 - val_loss: 0.3507 - learning_rate: 0.0050\n",
      "Epoch 11/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9616 - auc: 0.6577 - loss: 0.4827 - val_accuracy: 0.9419 - val_auc: 0.5376 - val_loss: 0.3241 - learning_rate: 0.0050\n",
      "Epoch 12/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9737 - auc: 0.6659 - loss: 0.3820 - val_accuracy: 0.9419 - val_auc: 0.5336 - val_loss: 0.3427 - learning_rate: 0.0050\n",
      "Epoch 13/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9662 - auc: 0.6849 - loss: 0.4445 - val_accuracy: 0.9419 - val_auc: 0.5384 - val_loss: 0.3439 - learning_rate: 0.0050\n",
      "Epoch 14/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9822 - auc: 0.6649 - loss: 0.2726 - val_accuracy: 0.9419 - val_auc: 0.5420 - val_loss: 0.3458 - learning_rate: 0.0050\n",
      "Epoch 15/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9719 - auc: 0.7188 - loss: 0.3714 - val_accuracy: 0.9419 - val_auc: 0.5216 - val_loss: 0.3549 - learning_rate: 0.0050\n",
      "Epoch 16/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9707 - auc: 0.6102 - loss: 0.3968 - val_accuracy: 0.9419 - val_auc: 0.5210 - val_loss: 0.3775 - learning_rate: 0.0050\n",
      "Epoch 17/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9751 - auc: 0.6847 - loss: 0.3471 - val_accuracy: 0.9419 - val_auc: 0.5278 - val_loss: 0.3802 - learning_rate: 0.0025\n",
      "Epoch 18/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9799 - auc: 0.6557 - loss: 0.3103 - val_accuracy: 0.9419 - val_auc: 0.5291 - val_loss: 0.3639 - learning_rate: 0.0025\n",
      "Epoch 19/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9659 - auc: 0.6869 - loss: 0.4394 - val_accuracy: 0.9419 - val_auc: 0.5325 - val_loss: 0.3553 - learning_rate: 0.0025\n",
      "Epoch 20/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9763 - auc: 0.7543 - loss: 0.3215 - val_accuracy: 0.9419 - val_auc: 0.5293 - val_loss: 0.3678 - learning_rate: 0.0025\n",
      "Epoch 21/300\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9737 - auc: 0.6768 - loss: 0.3636 - val_accuracy: 0.9419 - val_auc: 0.5213 - val_loss: 0.3871 - learning_rate: 0.0025\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5)\n",
    "\n",
    "history = model.fit(\n",
    "    x=[input_flux_band[train], input_flux_hist[train], input_additional[train]],\n",
    "    y=labels,\n",
    "    batch_size=32,\n",
    "    validation_split=0.5,\n",
    "    epochs=300,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3517fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Avvio ottimizzazione del decision boundary...\n",
      "------------------------------\n",
      "Soglia per Max Accuracy:  0.43 (Acc: 0.9262)\n",
      "Soglia per Equal Accuracy: 0.20 (Diff: 0.0016)\n",
      "------------------------------\n",
      "\n",
      "RISULTATI FINALI (Soglia 0.43):\n",
      "Accuracy: 0.9262\n",
      "F1 Score: 0.0000\n",
      "ROC AUC:  0.3325\n",
      "\n",
      "Matrice di Confusione:\n",
      "Predicted AGN | Predicted PSR\n",
      "True AGN: 2007           0\n",
      "True PSR: 160           0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# =============================================================================\n",
    "# 1. PREPARAZIONE DEI DATI E PREDISPOSIZIONE (Il fix per il tuo errore è qui)\n",
    "# =============================================================================\n",
    "\n",
    "# Ottieni le probabilità dalla rete neurale\n",
    "# Supponiamo che X_test siano i tuoi dati di test\n",
    "y_pred_probs = model.predict(\n",
    "    [input_flux_band[test], input_flux_hist[test], input_additional[test]]\n",
    ")\n",
    "y_test = labels[test]\n",
    "\n",
    "# GESTIONE DELLE ETICHETTE (FIX per ValueError)\n",
    "# Se y_test è in formato One-Hot (es. [[1, 0], [0, 1]]), lo convertiamo in indici [0, 1]\n",
    "# Classe 0 = AGN, Classe 1 = PSR\n",
    "if y_test.ndim > 1 and y_test.shape[1] > 1:\n",
    "    y_test_binary = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    y_test_binary = y_test\n",
    "\n",
    "# GESTIONE DELLE PROBABILITÀ\n",
    "# Se l'output è Softmax (N, 2), prendiamo la colonna 1 (probabilità di essere PSR)\n",
    "if y_pred_probs.shape[1] == 2:\n",
    "    y_scores = y_pred_probs[:, 1]\n",
    "else:\n",
    "    # Se l'output è Sigmoide (N, 1), lo appiattiamo\n",
    "    y_scores = y_pred_probs.flatten()\n",
    "\n",
    "# =============================================================================\n",
    "# 2. RICERCA DEL DECISION BOUNDARY OTTIMALE\n",
    "# =============================================================================\n",
    "# Il paper suggerisce di ottimizzare la soglia per massimizzare l'accuratezza\n",
    "# o per ottenere \"Equal Accuracy\" tra le classi[cite: 282, 285].\n",
    "\n",
    "thresholds = np.arange(0., 1.00, 0.001)\n",
    "\n",
    "best_acc = 0.0\n",
    "best_threshold = 0.5\n",
    "\n",
    "min_diff_equal_acc = 1.0\n",
    "equal_acc_threshold = 0.5\n",
    "\n",
    "print(\"Avvio ottimizzazione del decision boundary...\")\n",
    "\n",
    "for thresh in thresholds:\n",
    "    # Binarizza le predizioni in base alla soglia corrente\n",
    "    current_preds = (y_scores > thresh).astype(int)\n",
    "\n",
    "    # --- A. Calcolo Best Accuracy ---\n",
    "    acc = accuracy_score(y_test_binary, current_preds)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_threshold = thresh\n",
    "\n",
    "    # --- B. Calcolo Equal Accuracy ---\n",
    "    # Calcoliamo la matrice di confusione per questa soglia\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_binary, current_preds).ravel()\n",
    "\n",
    "    # Accuratezza sulla classe 0 (AGN) -> Specificity\n",
    "    acc_class_0 = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    # Accuratezza sulla classe 1 (PSR) -> Sensitivity/Recall\n",
    "    acc_class_1 = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    # Cerchiamo la soglia dove la differenza tra le due accuratezze è minima\n",
    "    diff = abs(acc_class_0 - acc_class_1)\n",
    "    if diff < min_diff_equal_acc:\n",
    "        min_diff_equal_acc = diff\n",
    "        equal_acc_threshold = thresh\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Soglia per Max Accuracy:  {best_threshold:.2f} (Acc: {best_acc:.4f})\")\n",
    "print(\n",
    "    f\"Soglia per Equal Accuracy: {equal_acc_threshold:.2f} (Diff: {min_diff_equal_acc:.4f})\"\n",
    ")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. VALUTAZIONE FINALE (Usando la soglia scelta)\n",
    "# =============================================================================\n",
    "\n",
    "# Scegli quale soglia usare (di solito Max Accuracy per performance generale)\n",
    "final_threshold = best_threshold\n",
    "y_final_pred = (y_scores > final_threshold).astype(int)\n",
    "\n",
    "# --- Calcolo Metriche ---\n",
    "\n",
    "# 1. Accuracy\n",
    "final_acc = accuracy_score(y_test_binary, y_final_pred)\n",
    "\n",
    "# 2. F1 Score (Importante per dataset sbilanciati come AGN >> PSR) [cite: 276]\n",
    "final_f1 = f1_score(y_test_binary, y_final_pred)\n",
    "\n",
    "# 3. ROC AUC (Indipendente dalla soglia, usa le probabilità grezze) [cite: 279]\n",
    "final_auc = roc_auc_score(y_test_binary, y_scores)\n",
    "\n",
    "# 4. Matrice di Confusione\n",
    "cm = confusion_matrix(y_test_binary, y_final_pred)\n",
    "\n",
    "print(f\"\\nRISULTATI FINALI (Soglia {final_threshold:.2f}):\")\n",
    "print(f\"Accuracy: {final_acc:.4f}\")\n",
    "print(f\"F1 Score: {final_f1:.4f}\")  \n",
    "print(f\"ROC AUC:  {final_auc:.4f}\")\n",
    "#print(f\"{met.class_accuracy(equal_acc_threshold,labels,y_scores)}\")\n",
    "print(\"\\nMatrice di Confusione:\")\n",
    "print(\"Predicted AGN | Predicted PSR\")\n",
    "print(f\"True AGN: {cm[0,0]}           {cm[0,1]}\")\n",
    "print(f\"True PSR: {cm[1,0]}           {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa0a4a",
   "metadata": {},
   "source": [
    "Avvio ottimizzazione del decision boundary...\n",
    "------------------------------\n",
    "Soglia per Max Accuracy:  0.45 (Acc: 0.9781)\n",
    "Soglia per Equal Accuracy: 0.03 (Diff: 0.0026)\n",
    "------------------------------\n",
    "\n",
    "RISULTATI FINALI (Soglia 0.45):\n",
    "Accuracy: 0.9781\n",
    "F1 Score: 0.8354\n",
    "ROC AUC:  0.9822\n",
    "(np.float64(0.9369706028898854), np.float64(0.934375))\n",
    "\n",
    "Matrice di Confusione:\n",
    "Predicted AGN | Predicted PSR\n",
    "True AGN: 3998           16\n",
    "True PSR: 79           241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a9655e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
