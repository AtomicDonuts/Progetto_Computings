{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7eb50d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21561,
     "status": "ok",
     "timestamp": 1765370228949,
     "user": {
      "displayName": "Pasquale Napoli",
      "userId": "02996346658187060776"
     },
     "user_tz": -60
    },
    "id": "bf7eb50d",
    "outputId": "2770de02-0aa1-46f8-f3e7-ef8607d2e975"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Colab Detected\")\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if not gpus:\n",
    "        raise RuntimeError(\"Nessuna GPU trovata.Controlla di aver selezionato il runtime giusto.\")\n",
    "    else:\n",
    "        print(f\"Trovate {len(gpus)} GPU:\\n{gpus}\")\n",
    "\n",
    "    !git clone https://github.com/AtomicDonuts/Progetto_Computings.git\n",
    "    %cd Progetto_Computings/\n",
    "    !git checkout modell\n",
    "    !pip install -q -r requirements.txt\n",
    "    !python3 fits_import/fits2csv.py\n",
    "\n",
    "    sys.path.append(\"imports/\")\n",
    "    import custom_variables as custom_paths\n",
    "    import ann_models as ann\n",
    "else:\n",
    "    print(\"Local Machine Detected\")\n",
    "    sys.path.append(\"../imports/\")\n",
    "    import custom_variables as custom_paths\n",
    "    import ann_models as ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09932349",
   "metadata": {
    "executionInfo": {
     "elapsed": 14338,
     "status": "ok",
     "timestamp": 1765372963725,
     "user": {
      "displayName": "Pasquale Napoli",
      "userId": "02996346658187060776"
     },
     "user_tz": -60
    },
    "id": "09932349"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ea645",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1765373034100,
     "user": {
      "displayName": "Pasquale Napoli",
      "userId": "02996346658187060776"
     },
     "user_tz": -60
    },
    "id": "d02ea645",
    "outputId": "1f4e9d8f-18fc-494b-857f-2afdc12f0759"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(custom_paths.csv_path)\n",
    "df = df[(df[\"CLASS_GENERIC\"] == \"AGN\") | (df[\"CLASS_GENERIC\"] == \"Pulsar\")]\n",
    "print(f\"Dataset Dimentions: {len(df)}\")\n",
    "\n",
    "df[\"PowerLaw\"] = np.where(df[\"SpectrumType\"] == \"PowerLaw\",1,0,)\n",
    "df[\"LogParabola\"] = np.where(df[\"SpectrumType\"] == \"LogParabola\",1,0,)\n",
    "df[\"PLSuperExpCutoff\"] = np.where(df[\"SpectrumType\"] == \"PLSuperExpCutoff\",1,0,)\n",
    "\n",
    "norm_cols = [\"GLAT\", \"PowerLaw\",\"LogParabola\",\"PLSuperExpCutoff\" ,\"Variability_Index\"]\n",
    "input_datas = df[norm_cols].to_numpy()\n",
    "\n",
    "is_agn = df[\"CLASS_GENERIC\"].to_numpy() == \"AGN\"\n",
    "is_psr = df[\"CLASS_GENERIC\"].to_numpy() == \"Pulsar\"\n",
    "labels = np.zeros((len(df)), dtype=int)\n",
    "labels[is_agn] = 0\n",
    "labels[is_psr] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239fc51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 234700,
     "status": "ok",
     "timestamp": 1765373295631,
     "user": {
      "displayName": "Pasquale Napoli",
      "userId": "02996346658187060776"
     },
     "user_tz": -60
    },
    "id": "3239fc51",
    "outputId": "d7925b70-1e55-4ded-889e-c9d8da856406"
   },
   "outputs": [],
   "source": [
    "num_splits = 10\n",
    "skf = StratifiedKFold(n_splits=num_splits, shuffle=True)\n",
    "fold_index = 1\n",
    "for a, b in skf.split(input_datas, labels):\n",
    "    train_inp = input_datas[a]\n",
    "    train_lab = labels[a]\n",
    "    val_inp = input_datas[b]\n",
    "    val_lab = labels[b]\n",
    "    tuner = kt.Hyperband(\n",
    "        ann.hp_model,\n",
    "        objective=\"accuracy\",\n",
    "        max_epochs=100,\n",
    "        factor=3,\n",
    "        overwrite=False,\n",
    "        directory=\"DNN\",\n",
    "        project_name=f\"Fold_{fold_index}\",\n",
    "    )\n",
    "    stop_early = keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=5)\n",
    "    tuner.search(\n",
    "        train_inp,\n",
    "        train_lab,\n",
    "        epochs=50,\n",
    "        validation_data=(val_inp, val_lab),\n",
    "        callbacks=[stop_early],\n",
    "    )\n",
    "    fold_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb836c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuners = []\n",
    "for i in range(1,num_splits+1):\n",
    "    tuners.append(kt.Hyperband(\n",
    "        ann.hp_model,\n",
    "        objective=\"accuracy\",\n",
    "        max_epochs=100,\n",
    "        factor=3,\n",
    "        overwrite=False,\n",
    "        directory=\"DNN\",\n",
    "        project_name=f\"Fold_{i}\",\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e77c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "dropout = []\n",
    "for j in tuners:\n",
    "    for i in j.get_best_hyperparameters(num_trials=3):\n",
    "        nodes.append(i.get(\"nodes\"))\n",
    "        dropout.append(i.get(\"dropout\"))\n",
    "modal_nodes = stats.mode(nodes).mode\n",
    "modal_dropout = stats.mode(dropout).mode\n",
    "\n",
    "print(f\"Modal Nodes: {modal_nodes}\")\n",
    "print(f\"Modal Dropout: {modal_dropout}\")\n",
    "\n",
    "best_matching_tuner = None\n",
    "highest_accuracy_matching_tuner = -1\n",
    "best_matching_tuner_index = -1\n",
    "\n",
    "print(\"Ricerca del tuner con iperparametri modali e massima accuratezza...\")\n",
    "\n",
    "for index, tuner_obj in enumerate(tuners):\n",
    "    \n",
    "    # Ottieni i migliori trial dal tuner\n",
    "    # tuner.oracle.get_best_trials() restituisce una lista di oggetti Trial\n",
    "    best_trial = tuner_obj.oracle.get_best_trials(num_trials=1)[0]\n",
    "    best_hps = best_trial.hyperparameters\n",
    "    current_accuracy = best_trial.score\n",
    "\n",
    "    current_nodes = best_hps.get(\"nodes\")\n",
    "    current_dropout = best_hps.get(\"dropout\")\n",
    "\n",
    "    # Controlla se i valori corrispondono alla moda\n",
    "    if current_nodes == modal_nodes and np.isclose(current_dropout, modal_dropout):\n",
    "        print(\n",
    "            f\"  Fold {index + 1} corrisponde. Accuratezza: {current_accuracy:.4f}\"\n",
    "        )\n",
    "        # Se corrisponde e ha un'accuratezza maggiore, aggiorna il miglior tuner\n",
    "        if current_accuracy > highest_accuracy_matching_tuner:\n",
    "            highest_accuracy_matching_tuner = current_accuracy\n",
    "            best_matching_tuner = tuner_obj\n",
    "            best_matching_tuner_index = index\n",
    "\n",
    "if best_matching_tuner:\n",
    "    print(\n",
    "        f\"\\nIl miglior tuner trovato con NODES={modal_nodes} e DROPOUT={modal_dropout} Ã¨ per la Fold {best_matching_tuner_index + 1} con Accuratezza: {highest_accuracy_matching_tuner:.4f}\"\n",
    "    )\n",
    "    print(\"I suoi migliori iperparametri sono:\\n\")\n",
    "    best_matching_tuner.results_summary(num_trials=1)\n",
    "    best_model = best_matching_tuner.get_best_models(num_models=1)[0]\n",
    "    # print(\"Sommario del miglior modello:\\n\")\n",
    "    # best_model.summary()\n",
    "else:\n",
    "    print(\n",
    "        \"Nessun tuner trovato con iperparametri che corrispondono esattamente ai valori della moda.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86756a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"accuracy\", patience=10, restore_best_weights=True\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"accuracy\", factor=0.5, patience=5)\n",
    "best_model.optimizer.learning_rate = 0.01\n",
    "history = best_model.fit(\n",
    "    input_datas,\n",
    "    labels,\n",
    "    epochs=300,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
