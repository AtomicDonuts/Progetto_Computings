{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Colab Detected\")\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if not gpus:\n",
    "        raise RuntimeError(\"Nessuna GPU trovata.Controlla di aver selezionato il runtime giusto.\")\n",
    "    else:\n",
    "        print(f\"Trovate {len(gpus)} GPU:\\n{gpus}\")\n",
    "    \n",
    "    !git clone https://github.com/AtomicDonuts/Progetto_Computings.git\n",
    "    %cd Progetto_Computings/\n",
    "    !git checkout modell\n",
    "    !pip install -q -r requirements.txt\n",
    "    !python3 fits_import/fits2csv.py\n",
    "    \n",
    "    sys.path.append(\"imports/\")\n",
    "    import nn_models as ann\n",
    "    import custom_variables as custom_paths\n",
    "    import metrics as met\n",
    "else:\n",
    "    print(\"Local Machine Detected\")\n",
    "    sys.path.append(\"../imports/\")\n",
    "    import nn_models as ann\n",
    "    import custom_variables as custom_paths\n",
    "    import metrics as met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "from scipy import stats\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(custom_paths.csv_path)\n",
    "df = df[(df[\"CLASS_GENERIC\"] == \"AGN\") | (df[\"CLASS_GENERIC\"] == \"Pulsar\")]\n",
    "print(f\"Sample Size: {len(df)}\")\n",
    "\n",
    "\n",
    "df[\"PowerLaw\"] = np.where(df[\"SpectrumType\"] == \"PowerLaw\",1,0,)\n",
    "df[\"LogParabola\"] = np.where(df[\"SpectrumType\"] == \"LogParabola\",1,0,)\n",
    "df[\"PLSuperExpCutoff\"] = np.where(df[\"SpectrumType\"] == \"PLSuperExpCutoff\",1,0,)\n",
    "\n",
    "\n",
    "col_input1 = [\"GLAT\", \"PowerLaw\",\"LogParabola\",\"PLSuperExpCutoff\"]\n",
    "\n",
    "col_flux_band = np.array([[f\"Flux_Band_{i}\", f\"Sqrt_TS_Band_{i}\"] for i in range(8)])\n",
    "col_flux_hist = np.array([[f\"Flux_History_{i}\", f\"Sqrt_TS_History_{i}\"] for i in range(14)])\n",
    "\n",
    "\n",
    "norm_cols = np.array(list(col_flux_band.flatten()) + list(col_flux_hist.flatten()))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[norm_cols])\n",
    "scaled_data = scaler.transform(df[norm_cols])\n",
    "df[norm_cols] = scaled_data\n",
    "\n",
    "\n",
    "input_additional = df[col_input1].to_numpy()\n",
    "input_flux_band = df[col_flux_band.flatten()].to_numpy()\n",
    "input_flux_hist = df[col_flux_hist.flatten()].to_numpy()\n",
    "print(f\"Additionl Size: {input_additional.shape}\")\n",
    "print(f\"Flux_Band Size: {input_flux_band.shape}\")\n",
    "print(f\"Flux_History Size: {input_flux_hist.shape}\")\n",
    "\n",
    "\n",
    "is_agn = df[\"CLASS_GENERIC\"].to_numpy() == \"AGN\"\n",
    "\n",
    "labels = np.zeros((len(df)), dtype=int)\n",
    "labels[~is_agn] = 1\n",
    "\n",
    "labels_double = np.zeros((len(df), 2), dtype=int)\n",
    "labels_double[is_agn, 0] = 1\n",
    "labels_double[~is_agn, 1] = 1\n",
    "\n",
    "\n",
    "class_weight = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=np.unique(labels), y=labels\n",
    ")\n",
    "class_weight = {index: value for index, value in enumerate(class_weight)}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "train, test = next(skf.split(np.zeros(len(labels)), labels))\n",
    "\n",
    "fb = input_flux_band[train]\n",
    "hb = input_flux_hist[train]\n",
    "ia = input_additional[train]\n",
    "lab = labels[train]\n",
    "vfb =  input_flux_band[test]\n",
    "vhb =  input_flux_hist[test]\n",
    "via = input_additional[test]\n",
    "vlab = labels[test]\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    ann.hp_final_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    overwrite=False,\n",
    "    directory=\"Finale\",\n",
    "    project_name=\"TriploInput\",\n",
    ")\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "tuner.search(\n",
    "    x=[fb, hb, ia],\n",
    "    y=lab,\n",
    "    epochs=50,\n",
    "    validation_split=0.5,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[stop_early],\n",
    ")\n",
    "\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5)\n",
    "history = best_model.fit(\n",
    "    x=[fb, hb, ia],\n",
    "    y=lab,\n",
    "    epochs=300,\n",
    "    validation_split=0.5,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------------------------------------\")\n",
    "print(\"Dataset Separato\")\n",
    "predictions = best_model.predict([vfb, vhb, via])\n",
    "acc, th = met.best_accuracy(vlab, predictions)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"F1 Score: {met.f1_score(th,vlab, predictions)}\")\n",
    "acc_agn, acc_psr = met.class_accuracy(th, vlab, predictions)\n",
    "print(f\"Accuracy AGN: {acc_agn} Accuracy PSR: {acc_psr}\")\n",
    "th_pred = (predictions >= th).astype(int)\n",
    "print(met.sk_metrics.confusion_matrix(vlab, th_pred))\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Tutto il Dataset\")\n",
    "print(\"Dataset Separato\")\n",
    "predictions = best_model.predict([input_flux_band, input_flux_hist, input_additional])\n",
    "acc, th = met.best_accuracy(labels, predictions)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"F1 Score: {met.f1_score(th,labels, predictions)}\")\n",
    "acc_agn, acc_psr = met.class_accuracy(th, labels, predictions)\n",
    "print(f\"Accuracy AGN: {acc_agn} Accuracy PSR: {acc_psr}\")\n",
    "th_pred = (predictions >= th).astype(int)\n",
    "print(met.sk_metrics.confusion_matrix(labels, th_pred))\n",
    "print(\"------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
