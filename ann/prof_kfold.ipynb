{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d3fc460",
      "metadata": {
        "id": "7d3fc460"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    print(\"Colab Detected\")\n",
        "    import tensorflow as tf\n",
        "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "    if not gpus:\n",
        "        raise RuntimeError(\"Nessuna GPU trovata.Controlla di aver selezionato il runtime giusto.\")\n",
        "    else:\n",
        "        print(f\"Trovate {len(gpus)} GPU:\\n{gpus}\")\n",
        "\n",
        "    !git clone https://github.com/AtomicDonuts/Progetto_Computings.git\n",
        "    %cd Progetto_Computings/\n",
        "    !pip install -q -r requirements.txt\n",
        "    !python3 fits_import/fits2csv.py\n",
        "\n",
        "    sys.path.append(\"imports/\")\n",
        "    import custom_variables as custom_paths\n",
        "else:\n",
        "    print(\"Local Machine Detected\")\n",
        "    sys.path.append(\"../imports/\")\n",
        "    import custom_variables as custom_paths\n",
        "    import nn_models as ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a83728e",
      "metadata": {
        "id": "2a83728e"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Input, Concatenate,Flatten, Dropout\n",
        "from keras.models import Model,Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed6986ad",
      "metadata": {
        "id": "ed6986ad"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(custom_paths.csv_path)\n",
        "df = df[(df[\"CLASS_GENERIC\"] == \"AGN\") | (df[\"CLASS_GENERIC\"] == \"Pulsar\")]\n",
        "print(f\"Dataset Dimentions: {len(df)}\")\n",
        "\n",
        "df[\"PowerLaw\"] = np.where(df[\"SpectrumType\"] == \"PowerLaw\",1,0,)\n",
        "df[\"LogParabola\"] = np.where(df[\"SpectrumType\"] == \"LogParabola\",1,0,)\n",
        "df[\"PLSuperExpCutoff\"] = np.where(df[\"SpectrumType\"] == \"PLSuperExpCutoff\",1,0,)\n",
        "\n",
        "norm_cols = [\"GLAT\", \"PowerLaw\",\"LogParabola\",\"PLSuperExpCutoff\" ,\"Variability_Index\"]\n",
        "input_datas = df[norm_cols].to_numpy()\n",
        "\n",
        "is_agn = df[\"CLASS_GENERIC\"].to_numpy() == \"AGN\"\n",
        "is_psr = df[\"CLASS_GENERIC\"].to_numpy() == \"Pulsar\"\n",
        "labels = np.zeros((len(df)), dtype=int)\n",
        "labels[is_agn] = 0\n",
        "labels[is_psr] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "167c708f",
      "metadata": {
        "id": "167c708f"
      },
      "outputs": [],
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "fold_no = 1\n",
        "skf = StratifiedKFold(n_splits=10,shuffle=True)\n",
        "for train,test in skf.split(input_datas,labels):\n",
        "    model = ann.simple_model(input_datas.shape[1:])\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\",\"auc\"],\n",
        "                )\n",
        "    model.optimizer.learning_rate = 0.01\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "    # early_stopping = EarlyStopping(\n",
        "    #     monitor=\"accuracy\",\n",
        "    #     patience=10,\n",
        "    #     restore_best_weights=True\n",
        "    # )\n",
        "    # reduce_lr = ReduceLROnPlateau(monitor=\"accuracy\", factor=0.5, patience=5)\n",
        "\n",
        "    history = model.fit(\n",
        "        input_datas[train],\n",
        "        labels[train],\n",
        "        #batch_size=,\n",
        "        #validation_split=0.5,\n",
        "        epochs=50,\n",
        "        #callbacks=[early_stopping,reduce_lr],\n",
        "        verbose = 2,\n",
        "    )\n",
        "    #scores = model.evaluate(input_datas[test], labels[test], verbose=0)\n",
        "    #print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    #loss_per_fold.append(scores)\n",
        "    #acc_per_fold.append(scores[1] * 100)\n",
        "    fold_no = fold_no + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7ad1883",
      "metadata": {},
      "outputs": [],
      "source": [
        "score = model.evaluate(input_datas,labels,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2a30268",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.metrics_names[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee83dff",
      "metadata": {
        "id": "cee83dff"
      },
      "outputs": [],
      "source": [
        "# == Provide average scores ==\n",
        "print(\"------------------------------------------------------------------------\")\n",
        "print(\"Score per fold\")\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "    print(\"------------------------------------------------------------------------\")\n",
        "    print(f\"> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%\")\n",
        "print(\"------------------------------------------------------------------------\")\n",
        "print(\"Average scores for all folds:\")\n",
        "print(f\"> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})\")\n",
        "print(f\"> Loss: {np.mean(loss_per_fold)}\")\n",
        "print(\"------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf3d1f53",
      "metadata": {},
      "outputs": [],
      "source": [
        "predicts = model.predict(input_datas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0684a93",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn.metrics as sk_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4449d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def best_accuracy(y_true, y_prob):\n",
        "    \"\"\"Trova la soglia che massimizza l'accuratezza sul training set.\"\"\"\n",
        "    thresholds = np.linspace(0, 1, 101)\n",
        "    best_threshold = 0.5\n",
        "    best_acc = 0.0\n",
        "    for t in thresholds:\n",
        "        y_pred = (y_prob >= t).astype(int)\n",
        "        acc = sk_metrics.accuracy_score(y_true, y_pred)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_threshold = t\n",
        "    return best_acc, best_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee8693e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def equal_accuracy(y_true, y_prob):\n",
        "    \"\"\"Trova la soglia che minimizza la differenza di accuratezza tra le classi.\"\"\"\n",
        "    thresholds = np.linspace(0, 1, 101)\n",
        "    best_threshold = 0.5\n",
        "    min_diff = 1.0\n",
        "    best_agn = 0\n",
        "    best_psr = 0\n",
        "    for t in thresholds:\n",
        "        y_pred = (y_prob >= t).astype(int)\n",
        "        cm = sk_metrics.confusion_matrix(y_true, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        acc_agn = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        acc_psr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        diff = abs(acc_agn - acc_psr)\n",
        "        if diff < min_diff:\n",
        "            min_diff = diff\n",
        "            best_agn = acc_agn\n",
        "            best_psr = acc_psr\n",
        "            best_threshold = t\n",
        "    return best_agn, best_psr, best_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2fc4aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "def f1_score_t(y_true, y_prob, threshold):\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "    cm = sk_metrics.confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    return tp / (tp + 0.5 * (fp + fn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d176df38",
      "metadata": {},
      "outputs": [],
      "source": [
        "def f1_score(y_true, y_prob):\n",
        "    thresholds = np.linspace(0, 1, 101)\n",
        "    best_threshold = 0.5\n",
        "    best_f1 = 0.0\n",
        "    for t in thresholds:\n",
        "        y_pred = (y_prob >= t).astype(int)\n",
        "        cm = sk_metrics.confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        f1 = tp / (tp + 0.5 * (fp + fn))\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = t\n",
        "    return best_f1, best_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55cbeae2",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = (predicts >= 0.003).astype(int)\n",
        "cm = sk_metrics.confusion_matrix(y_true, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "acc_agn = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "acc_psr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "print(acc_agn,acc_psr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b43278",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(best_accuracy(labels,predicts))\n",
        "print(equal_accuracy(labels,predicts))\n",
        "print(f1_score(labels,predicts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4da68112",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = (predicts >= 0.8).astype(int)\n",
        "y_true = labels\n",
        "acc = sk_metrics.accuracy_score(y_true, y_pred)\n",
        "print(acc - best_accuracy(y_true, predicts)[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
